{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n [ 1.  2.]\n [ 1.  3.]\n [ 1.  4.]\n [ 1.  5.]\n [ 1.  6.]\n [ 1.  7.]\n [ 1.  8.]\n [ 1.  9.]\n [ 1. 10.]\n [ 1. 11.]\n [ 1. 12.]\n [ 1. 13.]\n [ 1. 14.]\n [ 1. 15.]\n [ 1. 16.]\n [ 1. 17.]\n [ 1. 18.]\n [ 1. 19.]\n [ 1. 20.]]\n[[ 3]\n [ 4]\n [ 5]\n [ 5]\n [ 2]\n [ 4]\n [ 7]\n [ 8]\n [11]\n [ 8]\n [12]\n [11]\n [13]\n [13]\n [16]\n [17]\n [18]\n [17]\n [19]\n [21]]\noptimal: [[0.51583286]\n [0.96992163]]\nerror function: 405.98496249324046\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Size of the points dataset.\n",
    "m = 20\n",
    "#定义数据集和学习率\n",
    "# Points x-coordinate and dummy value (x0, x1).\n",
    "#ones生成初始值为1，长度为m的一位数组 zeros()初始值为0\n",
    "X0 = np.ones((m, 1))\n",
    "#arange(x,y) 一维数组 x是间隔  y是数组最后一位上限，不包含y \n",
    "#reshape 将一位数组转换成二维数组，reshape(x,y)x行y列 x*y=一位数组的长度\n",
    "X1 = np.arange(1, m+1).reshape(m, 1)\n",
    "X = np.hstack((X0, X1))\n",
    "print(X)\n",
    "\n",
    "# Points y-coordinate\n",
    "y = np.array([\n",
    "    3, 4, 5, 5, 2, 4, 7, 8, 11, 8, 12,\n",
    "    11, 13, 13, 16, 17, 18, 17, 19, 21\n",
    "]).reshape(m, 1)\n",
    "print(y)\n",
    "# The Learning Rate alpha.\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "#以矩阵向量的形式定义代价函数和代价函数的梯度\n",
    "def error_function(theta, X, y):\n",
    "    '''Error function J definition.'''\n",
    "    diff = np.dot(X, theta) - y\n",
    "    return (1./2*m) * np.dot(np.transpose(diff), diff)\n",
    "\n",
    "def gradient_function(theta, X, y):\n",
    "    '''Gradient of the function J definition.'''\n",
    "    diff = np.dot(X, theta) - y\n",
    "    # print(diff)\n",
    "    # grd = np.dot(np.transpose(X), diff)\n",
    "    # print(grd)\n",
    "    return (1./m) * np.dot(np.transpose(X), diff)\n",
    "\n",
    "def gradient_descent(X, y, alpha):\n",
    "    '''Perform gradient descent.'''\n",
    "    theta = np.array([1, 1]).reshape(2, 1)\n",
    "    gradient = gradient_function(theta, X, y)\n",
    "    while not np.all(np.absolute(gradient) <= 1e-5):\n",
    "        theta = theta - alpha * gradient\n",
    "        gradient = gradient_function(theta, X, y)\n",
    "    return theta\n",
    "\n",
    "optimal = gradient_descent(X, y, alpha)\n",
    "print('optimal:', optimal)\n",
    "print('error function:', error_function(optimal, X, y)[0,0])\n",
    "# theta = np.array([1, 1]).reshape(2, 1)\n",
    "# \n",
    "# gradient = gradient_function(theta, X, y)\n",
    "# print(gradient)\n",
    "# ress= np.absolute(gradient)\n",
    "# print(ress > 3)\n",
    "# print(ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dc5aa8af8235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#以矩阵向量的形式定义代价函数和代价函数的梯度\n",
    "def error_function(theta, X, y):\n",
    "    '''Error function J definition.'''\n",
    "    diff = np.dot(X, theta) - y\n",
    "    return (1./2*m) * np.dot(np.transpose(diff), diff)\n",
    "\n",
    "def gradient_function(theta, X, y):\n",
    "    '''Gradient of the function J definition.'''\n",
    "    diff = np.dot(X, theta) - y\n",
    "    return (1./m) * np.dot(np.transpose(X), diff)\n",
    "\n",
    "\n",
    "theta = np.array([1, 1]).reshape(2, 1)\n",
    "\n",
    "gradient = gradient_function(theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_function' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0298bd5952aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gradient_function' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n [2]]\n[[1 2]\n [3 4]]\n[[False False]\n [False  True]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.arange(1, 3).reshape(2,1) #.reshape(m, 1)\n",
    "print(X1)\n",
    "test2 = np.arange(1,5).reshape(2,2)\n",
    "print(test2)\n",
    "print(test2 > 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
